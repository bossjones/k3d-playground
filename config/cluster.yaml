apiVersion: k3d.io/v1alpha5
kind: Simple
metadata:
  name: demo
servers: 1
agents: 3
kubeAPI:
  host: "k8s.localhost"
  # hostIP: "127.0.0.1"
  hostIP: "0.0.0.0"
  hostPort: "6445"
image: rancher/k3s:v1.27.4-k3s1
network: demo-net
ports:
- port: 80:80
  nodeFilters:
  - loadbalancer
- port: 443:443
  nodeFilters:
  - loadbalancer

# SOURCE: https://github.com/bravecobra/k8s-dev-infrastructure/blob/adb085443cffb00a69c2ddc4a415f02ef785d79a/src/clusters/k3d/devinfra-template.yaml#L2
- port: 8100:8100 # same as `--port '8100:8100@loadbalancer'`
  nodeFilters:
    - loadbalancer

# - port: 30000:30000
#   nodeFilters:
#     - loadbalancer
# - port: 8080:8080
#   nodeFilters:
#     - loadbalancer
# - port: 9201:9201
#   nodeFilters:
#     - loadbalancer
# - port: 80:80
#   nodeFilters:
#     - loadbalancer
# - port: 443:443
#   nodeFilters:
#     - loadbalancer
# - port: 9090:9090
#   nodeFilters:
#     - loadbalancer
# - port: 8081:8081
#   nodeFilters:
#     - loadbalancer
# - port: 9091:9091
#   nodeFilters:
#     - loadbalancer

# #
# #%{ if expose_azurite == true }
# - port: 10000:10000 # same as `--port '10000:10000@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# - port: 10001:10001 # same as `--port '10001:10001@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# - port: 10002:10002 # same as `--port '10002:10002@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_seq == true }
# - port: 5341:5341 # same as `--port '5341:5341@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_opentelemetry == true }
# - port: 4317:4317 # same as `--port '4317:4317@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# - port: 4318:4318 # same as `--port '4318:4318@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_jaeger == true }
# - port: 6831:6831 # same as `--port '6831:6831@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# - port: 6832:6832 # same as `--port '6832:6832@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_rabbitmq == true }
# - port: 5672:5672 # same as `--port '5672:5672@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_loki == true }
# - port: 3100:3100 # same as `--port '3100:3100@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_rds_mssql == true }
# - port: 1433:1433 # same as `--port '1433:1433@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_rds_oracle == true }
# - port: 1521:1521 # same as `--port '1521:1521@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_rds_mysql == true }
# - port: 3306:3306 # same as `--port '3306:3306@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_rds_mysql == true }
# - port: 3307:3307 # same as `--port '3306:3306@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_rds_postgres == true }
# - port: 5432:5432 # same as `--port '5432:5432@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_nosql_mongodb == true }
# - port: 27017:27017 # same as `--port '27017:27017@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }

# #%{ if expose_redis == true }
# - port: 6379:6379 # same as `--port '6379:6379@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# #%{ endif }
# #%{ if expose_grafana == true }
# - port: 3000:3000 # same as `--port '6379:6379@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
#%{ endif }
# - port: 5053:53/udp
#   nodeFilters:
#   - agent:0:direct
# # https://github.com/bravecobra/k8s-e2e/blob/fe1370ae14ca9bed95523b122cca67c9e937ab44/k3s-devinfra.yaml#L2
# - port: 8100:8100 # same as `--port '8100:8100@loadbalancer'`
#   nodeFilters:
#     - loadbalancer
# - port: 8080:8080
#   nodeFilters:
#   - loadbalancer
registries:
  create:
    name: registry.localhost
    host: "0.0.0.0"
    hostPort: "5002"
  config: |
    mirrors:
      "registry.localhost":
        endpoint:
          - http://registry.local.gd:5002

volumes:
- volume: "${PWD}/storage:/var/lib/rancher/k3s/storage"
  nodeFilters:
  - server:0
  - agent:*
- volume: "${PWD}/audit/audit.yaml:/var/lib/rancher/k3s/server/manifests/audit.yaml"
  nodeFilters:
  - server:*
- volume: "${PWD}/audit/logs:/var/log/kubernetes/audit"
  nodeFilters:
  - server:*
# SOURCE: https://github.com/defenseunicorns/uds-capability-confluence/blob/90b30c74d83f0aa4ec404a840b92a5956f921195/utils/k3d/k3d-config.yaml#L2
# - volume: /etc/machine-id:/etc/machine-id
#   nodeFilters:
#     - server:*
# - volume: /sys/fs/bpf:/sys/fs/bpf:shared
#   nodeFilters:
#     - server:*
  # --volume {{PWD}}:/var/lib/rancer/k3s/server/manifests/traefik-config.yaml@all \
  # --volume /tmp/k3dvol:/var/lib/rancher/k3s/storage@all \
hostAliases:
- ip: 127.0.0.1
  hostnames:
  - k8s.localhost
  - app.k8s.localhost
  - example.k8s.localhost
  - argocd.k8s.localhost
  # - argocd.k8s.localhost
  - postgres.k8s.localhost
  - dbs.k8s.localhost
options:
  k3d:
    wait: true
    timeout: "360s"
    loadbalancer:
      configOverrides:
      - settings.workerConnections=2048
  k3s:
    extraArgs:
    # - arg: "--debug"
    #   nodeFilters:
    #     - server:*
    #     - agent:*
    # - arg: "--write-kubeconfig-mode 644"
    #   nodeFilters:
    #     - server:*
    # - arg: "--write-kubeconfig ~/.kube/config"
    #   nodeFilters:
    #     - server:*
    - arg: --disable=traefik
      nodeFilters:
      - server:*
    - arg: --disable=metrics-server
      nodeFilters:
      - server:*
    # - arg: --disable-network-policy
    #   nodeFilters:
    #     - server:*
    - arg: --tls-san=localhost,registry.local.gd,127.0.0.1,registry.localhost,k8s.localhost,whoami.k8s.localhost
      nodeFilters:
      - server:*
    - arg: --kube-proxy-arg=metrics-bind-address=0.0.0.0
      nodeFilters:
      - server:*
      - agent:*
    # FIXME: I think we need to re-enable these but I need help doing it # - arg: --kube-scheduler-arg=bind-address=0.0.0.0
    # FIXME: I think we need to re-enable these but I need help doing it #   nodeFilters:
    # FIXME: I think we need to re-enable these but I need help doing it #   - server:*
    # FIXME: I think we need to re-enable these but I need help doing it # - arg: --kube-scheduler-arg=address=0.0.0.0
    # FIXME: I think we need to re-enable these but I need help doing it #   nodeFilters:
    # FIXME: I think we need to re-enable these but I need help doing it #   - server:*
    # FIXME: I think we need to re-enable these but I need help doing it # - arg: --kube-controller-manager-arg=bind-address=0.0.0.0
    # FIXME: I think we need to re-enable these but I need help doing it #   nodeFilters:
    # FIXME: I think we need to re-enable these but I need help doing it #   - server:*
    # FIXME: I think we need to re-enable these but I need help doing it # - arg: --etcd-expose-metrics=true
    # FIXME: I think we need to re-enable these but I need help doing it #   nodeFilters:
    # FIXME: I think we need to re-enable these but I need help doing it #   - server:*
    # FIXME: I think we need to re-enable these but I need help doing it # - arg: --kube-controller-manager-arg=address=0.0.0.0
    # FIXME: I think we need to re-enable these but I need help doing it #   nodeFilters:
    # FIXME: I think we need to re-enable these but I need help doing it #   - server:*
    - arg: --kubelet-arg=node-status-update-frequency=4s
      nodeFilters:
      - server:*
    - arg: --kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%
      nodeFilters:
      - agent:*
    - arg: --kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%
      nodeFilters:
      - agent:*
    - arg: --kubelet-arg=eviction-hard=imagefs.available<1%,nodefs.available<1%
      nodeFilters:
      - server:*
    - arg: --kubelet-arg=eviction-minimum-reclaim=imagefs.available=1%,nodefs.available=1%
      nodeFilters:
      - server:*
    - arg: --kube-apiserver-arg=audit-policy-file=/var/lib/rancher/k3s/server/manifests/audit.yaml
      nodeFilters:
      - server:*
    - arg: --kube-apiserver-arg=audit-log-path=/var/log/kubernetes/audit/audit.log
      nodeFilters:
      - server:*
    - arg: --kube-apiserver-arg=v=3
      nodeFilters:
      - server:*
    - arg: --kube-scheduler-arg=v=3
      nodeFilters:
      - server:*
    # - arg: --kube-proxy-arg=v=3
    #   nodeFilters:
    #   - server:*
    # - arg: --kube-controller-manager-arg=v=3
    #   nodeFilters:
    #   - server:*

    # https://github.com/chainguard-dev/actions/blob/ce8f95bff0df14286adebc33bf1617f91288caea/setup-k3d/action.yaml#L78
    # # This is needed in order to support projected volumes with service account tokens.
    # # See:
    # #   https://kubernetes.slack.com/archives/CEKK1KTN2/p1600268272383600
    # #   https://stackoverflow.com/questions/74603633/k3s-allow-unauthenticated-access-to-oidc-endpoints
    # - arg: --kube-apiserver-arg=anonymous-auth=true
    #   nodeFilters:
    #     - server:*
    # # This sets the issuer to what sigstore scaffolding expects.
    # # See also: https://github.com/k3d-io/k3d/issues/1187
    # - arg: --kube-apiserver-arg=service-account-issuer=https://kubernetes.default.svc
    #   nodeFilters:
    #     - server:*
    # - arg: --kubelet-arg=max-pods=${{ inputs.max-pods }}
    #   nodeFilters:
    #     - server:*
    #     - agent:*

    # SOURCE: https://github.com/owncloud-docker/helm-charts/blob/d183f212988cb3530d28dbe4e409aaf0b862af2a/ci/k3d-drone.yaml#L2
    # - arg: --tls-san=k3d
    #   nodeFilters:
    #     - server:*
    # - arg: --disable=servicelb
    #   nodeFilters:
    #     - server:*
    # - arg: --disable=local-storage
    #   nodeFilters:
    #     - server:*
    # - arg: --flannel-backend=none
    #   nodeFilters:
    #     - server:*
  kubeconfig:
    updateDefaultKubeconfig: true
    switchCurrentContext: true

  runtime: # runtime (docker) specific options
    ulimits:
      - name: nofile
        soft: 26677
        hard: 26677
      - name: nproc
        soft: 26677
        hard: 26677
      - name: core
        soft: 26677
        hard: 26677
